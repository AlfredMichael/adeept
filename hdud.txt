import cv2
from picamera2 import Picamera2
from ultralytics import YOLO

# Load YOLO model
model = YOLO("yolov8n.pt")

# Define allowed classes
allowed_classes = [
    "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat",
    "cat", "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe",
    "backpack", "skateboard", "surfboard", "snowboard", "cell phone", "remote"
]

# Initialize camera
picam2 = Picamera2()
picam2.start()

while True:
    frame = picam2.capture_array()
    frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)

    # Run YOLOv8 inference
    results = model(frame)

    # Filter detections
    filtered_results = [r for r in results[0] if r.names[r.cls[0]] in allowed_classes]

    # Plot filtered results
    annotated_frame = results[0].plot(filtered_results)

    cv2.imshow("Filtered YOLOv8 Detection", annotated_frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cv2.destroyAllWindows()
picam2.stop()




------------Mock where these objects are?

Traceback (most recent call last):
  File "/home/fredthedev/ATREUS/TestModelInference.py", line 30, in <module>
    class_name = result.names[result.cls[0]]
  File "/home/fredthedev/ATREUS/atreus_venv/lib/python3.11/site-packages/ultralytics/utils/__init__.py", line 241, in __getattr__
    raise AttributeError(f"'{name}' object has no attribute '{attr}'. See valid attributes below.\n{self.__doc__}")
AttributeError: 'Boxes' object has no attribute 'names'. See valid attributes below.

    A class for managing and manipulating detection boxes.

    This class provides functionality for handling detection boxes, including their coordinates, confidence scores,
    class labels, and optional tracking IDs. It supports various box formats and offers methods for easy manipulation
    and conversion between different coordinate systems.

    Attributes:
        data (torch.Tensor | numpy.ndarray): The raw tensor containing detection boxes and associated data.
        orig_shape (Tuple[int, int]): The original image dimensions (height, width).
        is_track (bool): Indicates whether tracking IDs are included in the box data.
        xyxy (torch.Tensor | numpy.ndarray): Boxes in [x1, y1, x2, y2] format.
        conf (torch.Tensor | numpy.ndarray): Confidence scores for each box.
        cls (torch.Tensor | numpy.ndarray): Class labels for each box.
        id (torch.Tensor | None): Tracking IDs for each box (if available).
        xywh (torch.Tensor | numpy.ndarray): Boxes in [x, y, width, height] format.
        xyxyn (torch.Tensor | numpy.ndarray): Normalized [x1, y1, x2, y2] boxes relative to orig_shape.
        xywhn (torch.Tensor | numpy.ndarray): Normalized [x, y, width, height] boxes relative to orig_shape.

    Methods:
        cpu(): Returns a copy of the object with all tensors on CPU memory.
        numpy(): Returns a copy of the object with all tensors as numpy arrays.
        cuda(): Returns a copy of the object with all tensors on GPU memory.
        to(*args, **kwargs): Returns a copy of the object with tensors on specified device and dtype.

    Examples:
        >>> import torch
        >>> boxes_data = torch.tensor([[100, 50, 150, 100, 0.9, 0], [200, 150, 300, 250, 0.8, 1]])
        >>> orig_shape = (480, 640)  # height, width
        >>> boxes = Boxes(boxes_data, orig_shape)
        >>> print(boxes.xyxy)
        >>> print(boxes.conf)
        >>> print(boxes.cls)
        >>> print(boxes.xywhn)





------------------------------------------------------




from picamera2 import Picamera2
import cv2
from ultralytics import YOLO

picam2 = Picamera2()
picam2.start()

model = YOLO("yolov8n.pt")

while True:
    frame = picam2.capture_array()  # Get the live camera frame

    results = model.predict(frame)  # Run YOLO detection

    cv2.imshow("YOLOv8 Live Detection", frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cv2.destroyAllWindows()
picam2.close()





import cv2
from ultralytics import YOLO

model = YOLO("yolov8n.pt")

cap = cv2.VideoCapture(0)  # Open the default camera

while True:
    ret, frame = cap.read()
    if not ret:
        break

    results = model.predict(frame)  # Run YOLO detection
    cv2.imshow("YOLOv8 Live Detection", frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows()





from picamera2 import Picamera2
import cv2

picam2 = Picamera2()
picam2.start()
frame = picam2.capture_array()

cv2.imshow("Picamera2 Test", frame)
cv2.waitKey(0)
cv2.destroyAllWindows()
picam2.close()








--------------------------------------------------------------------------------------
import cv2
from picamera2 import Picamera2
from ultralytics import YOLO

# Initialize the camera
picam2 = Picamera2()
picam2.preview_configuration.main.size = (640, 480)  # Set resolution
picam2.preview_configuration.main.format = "RGB888"  # Set color format
picam2.configure("preview")
picam2.start()

# Load YOLOv8 model
model = YOLO("yolov8n.pt")  # You can use "yolov8s.pt" for a stronger model

while True:
    # Capture frame from camera
    frame = picam2.capture_array()

    # Perform YOLOv8 object detection
    results = model.predict(frame)

    # Draw bounding boxes on detected objects
    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = box.xyxy[0].tolist()
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)

    # Display the frame with detections
    cv2.imshow("YOLOv8 Live Detection", frame)

    # Exit if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

# Cleanup
cv2.destroyAllWindows()
picam2.close()
