import cv2
from picamera2 import Picamera2
from ultralytics import YOLO

# Load YOLO model
model = YOLO("yolov8n.pt")

# Define allowed classes
allowed_classes = [
    "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat",
    "cat", "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe",
    "backpack", "skateboard", "surfboard", "snowboard", "cell phone", "remote"
]

# Initialize camera
picam2 = Picamera2()
picam2.start()

while True:
    frame = picam2.capture_array()
    frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)

    # Run YOLOv8 inference
    results = model(frame)

    # Filter detections
    filtered_results = [r for r in results[0] if r.names[r.cls[0]] in allowed_classes]

    # Plot filtered results
    annotated_frame = results[0].plot(filtered_results)

    cv2.imshow("Filtered YOLOv8 Detection", annotated_frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cv2.destroyAllWindows()
picam2.stop()




------------Mock where these objects are?

import cv2
from picamera2 import Picamera2
from ultralytics import YOLO

# Load YOLO model
model = YOLO("yolov8n.pt")

# Define allowed classes
allowed_classes = [
    "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat",
    "cat", "dog", "horse", "sheep", "cow", "elephant", "bear", "zebra", "giraffe",
    "backpack", "skateboard", "surfboard", "snowboard", "cell phone", "remote"
]

# Initialize camera
picam2 = Picamera2()
picam2.start()

# Mocked servo positions (default center)
servo_x, servo_y = 90, 90

while True:
    frame = picam2.capture_array()
    frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)

    # Run YOLOv8 inference
    results = model(frame)

    for result in results[0].boxes:
        class_index = int(result.cls[0])  # Convert class tensor to an integer index
        class_name = model.names[class_index]  # Map index to class name

        if class_name in allowed_classes:  # Only track selected objects
            x_center = (result.xywh[0][0]).item()
            y_center = (result.xywh[0][1]).item()

            # Adjust servo movement based on object position
            servo_x = int(90 + (x_center - frame.shape[1] / 2) / 10)
            servo_y = int(90 + (y_center - frame.shape[0] / 2) / 10)

            print(f"Detected: {class_name} | Servo X: {servo_x}° | Servo Y: {servo_y}°")

    # Display the frame
    cv2.imshow("YOLOv8 Object Tracking", frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cv2.destroyAllWindows()
picam2.stop()





------------------------------------------------------




from picamera2 import Picamera2
import cv2
from ultralytics import YOLO

picam2 = Picamera2()
picam2.start()

model = YOLO("yolov8n.pt")

while True:
    frame = picam2.capture_array()  # Get the live camera frame

    results = model.predict(frame)  # Run YOLO detection

    cv2.imshow("YOLOv8 Live Detection", frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cv2.destroyAllWindows()
picam2.close()





import cv2
from ultralytics import YOLO

model = YOLO("yolov8n.pt")

cap = cv2.VideoCapture(0)  # Open the default camera

while True:
    ret, frame = cap.read()
    if not ret:
        break

    results = model.predict(frame)  # Run YOLO detection
    cv2.imshow("YOLOv8 Live Detection", frame)

    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

cap.release()
cv2.destroyAllWindows()





from picamera2 import Picamera2
import cv2

picam2 = Picamera2()
picam2.start()
frame = picam2.capture_array()

cv2.imshow("Picamera2 Test", frame)
cv2.waitKey(0)
cv2.destroyAllWindows()
picam2.close()








--------------------------------------------------------------------------------------
import cv2
from picamera2 import Picamera2
from ultralytics import YOLO

# Initialize the camera
picam2 = Picamera2()
picam2.preview_configuration.main.size = (640, 480)  # Set resolution
picam2.preview_configuration.main.format = "RGB888"  # Set color format
picam2.configure("preview")
picam2.start()

# Load YOLOv8 model
model = YOLO("yolov8n.pt")  # You can use "yolov8s.pt" for a stronger model

while True:
    # Capture frame from camera
    frame = picam2.capture_array()

    # Perform YOLOv8 object detection
    results = model.predict(frame)

    # Draw bounding boxes on detected objects
    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = box.xyxy[0].tolist()
            cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)

    # Display the frame with detections
    cv2.imshow("YOLOv8 Live Detection", frame)

    # Exit if 'q' is pressed
    if cv2.waitKey(1) & 0xFF == ord("q"):
        break

# Cleanup
cv2.destroyAllWindows()
picam2.close()
